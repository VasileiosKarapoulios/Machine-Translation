{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyODTztr1ImZqK0kxl0RYhQ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VasileiosKarapoulios/Machine-Translation/blob/main/PyTorch_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IRPrTXq-rrCH"
      },
      "source": [
        "!python -m spacy download en\n",
        "!python -m spacy download el\n",
        "!pip install torchtext==0.6.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GuvLAYWQjuzy"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.data.metrics import bleu_score\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torchtext.datasets import Multi30k\n",
        "from torchtext.data import Field, BucketIterator, TabularDataset\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import spacy\n",
        "import os\n",
        "import pandas as pd\n",
        "import sys\n",
        "import numpy as np\n",
        "import random "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0RSIicUbW0g"
      },
      "source": [
        "def translate(model, sentence, greek, english, device, max_length=50):\n",
        "    # Load greek tokenizer\n",
        "    spacy_el = spacy.load(\"el\")\n",
        "\n",
        "    # Create tokens using spacy and everything in lower case (which is what our vocab is)\n",
        "    if type(sentence) == str:\n",
        "        tokens = [token.text.lower() for token in spacy_el(sentence)]\n",
        "    else:\n",
        "        tokens = [token.lower() for token in sentence]\n",
        "\n",
        "    # Add <sos> and <eos> in beginning and in the end \n",
        "    tokens.insert(0, greek.init_token)\n",
        "    tokens.append(greek.eos_token)\n",
        "\n",
        "    # Go through each greek token and convert to an index\n",
        "    text_to_indices = [greek.vocab.stoi[token] for token in tokens]\n",
        "\n",
        "    # Convert to Tensor\n",
        "    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n",
        "\n",
        "    outputs = [english.vocab.stoi[\"<sos>\"]]\n",
        "    for i in range(max_length):\n",
        "        tgt_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(sentence_tensor, tgt_tensor)\n",
        "\n",
        "        prediction = output.argmax(2)[-1, :].item()\n",
        "        outputs.append(prediction)\n",
        "\n",
        "        if prediction == english.vocab.stoi[\"<eos>\"]:\n",
        "            break\n",
        "\n",
        "    translated = [english.vocab.itos[idx] for idx in outputs]\n",
        "\n",
        "    # remove start token\n",
        "    return translated[1:]\n",
        "\n",
        "def bleu(data, model, greek, english, device):\n",
        "    targets = []\n",
        "    outputs = []\n",
        "\n",
        "    for sentence in data:\n",
        "        src = vars(sentence)[\"Greek\"]\n",
        "        tgt = vars(sentence)[\"English\"]\n",
        "\n",
        "        prediction = translate(model, src, greek, english, device)\n",
        "\n",
        "        # remove <eos> token\n",
        "        prediction = prediction[:-1]  \n",
        "\n",
        "        targets.append([tgt])\n",
        "        outputs.append(prediction)\n",
        "    return bleu_score(outputs, targets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCBqXNvzbWxX",
        "outputId": "070c1433-fe8a-46ca-d580-69d9d90f4c10"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HVB2N1t7-hp"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "seed=42\n",
        "torch.manual_seed(seed)\n",
        "np.random.seed(seed)\n",
        "random.seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UO0IISYMbWrE"
      },
      "source": [
        "df = pd.read_csv(\"/content/drive/My Drive/EN-EL.txt\", sep='\\t', header = None)[[0,1]].rename(columns = {0:\"English\", 1:\"Greek\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2T11H9HwPss"
      },
      "source": [
        "# remove very long and very short sentences and sentences where translations are \n",
        "# not of roughly equal length\n",
        "df['eng_len'] = df['English'].str.count(' ')\n",
        "df['el_len'] = df['Greek'].str.count(' ')\n",
        "df = df.query('el_len < 100')\n",
        "df = df.query('eng_len < 100')\n",
        "df = df.query('el_len > 4 & eng_len > 4')\n",
        "df = df.query('el_len < eng_len * 1.5 & el_len * 1.5 > eng_len')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeBHixC7xg3G"
      },
      "source": [
        "df = df.drop('eng_len', 1)\n",
        "df = df.drop('el_len', 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1Rg9q0Zx_kt"
      },
      "source": [
        "df = df[:42000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "akSZx8oVwjZi",
        "outputId": "67c64d8e-6478-47eb-8926-edf3980fe465"
      },
      "source": [
        "df.English[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'fixing the minimum selling prices for butter for the 150th individual invitation to tender under the standing invitation to tender provided for in Regulation (EC) No 2571/97'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "A43lD1gHQ81I",
        "outputId": "339d9353-82b1-48b3-affc-dec1da98571a"
      },
      "source": [
        "df.Greek[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'για καθορισμό των ελαχίστων τιμών πώλησης βουτύρου για την 150η ειδική δημοπρασία που πραγματοποιείται στο πλαίσιο της διαρκούς δημοπρασίας που προβλέπεται από τον κανονισμό (ΕΚ) αριθ. 2571/97'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "DXVu7gSvbWpD",
        "outputId": "97e85d06-bcb5-434d-8404-5050b4367ff3"
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>English</th>\n",
              "      <th>Greek</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>fixing the minimum selling prices for butter f...</td>\n",
              "      <td>για καθορισμό των ελαχίστων τιμών πώλησης βουτ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Having regard to the Treaty establishing the E...</td>\n",
              "      <td>Έχοντας υπόψη: τη συνθήκη για την ίδρυση της Ε...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Having regard to Council Regulation (EC) No 12...</td>\n",
              "      <td>τον κανονισμό (ΕΚ) αριθ. 1255/1999 του Συμβουλ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The intervention agencies are, pursuant to Com...</td>\n",
              "      <td>Σύμφωνα με τον κανονισμό (ΕΚ) αριθ. 2571/97 τη...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The amount(s) of the processing securities mus...</td>\n",
              "      <td>Πρέπει συνεπώς να καθοριστούν το ή τα ποσά των...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The measures provided for in this Regulation a...</td>\n",
              "      <td>Τα μέτρα που προβλέπονται στον παρόντα κανονισ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The minimum selling prices of butter from inte...</td>\n",
              "      <td>Για την 150η ειδική δημοπρασία στο πλαίσιο της...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>This Regulation shall enter into force on 16 O...</td>\n",
              "      <td>Ο παρών κανονισμός αρχίζει να ισχύει στις 16 Ο...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>This Regulation shall be binding in its entire...</td>\n",
              "      <td>Ο παρών κανονισμός είναι δεσμευτικός ως προς ό...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>to the Commission Regulation of 15 October 200...</td>\n",
              "      <td>του κανονισμού της Επιτροπής, της 15ης Οκτωβρί...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              English                                              Greek\n",
              "2   fixing the minimum selling prices for butter f...  για καθορισμό των ελαχίστων τιμών πώλησης βουτ...\n",
              "4   Having regard to the Treaty establishing the E...  Έχοντας υπόψη: τη συνθήκη για την ίδρυση της Ε...\n",
              "5   Having regard to Council Regulation (EC) No 12...  τον κανονισμό (ΕΚ) αριθ. 1255/1999 του Συμβουλ...\n",
              "7   The intervention agencies are, pursuant to Com...  Σύμφωνα με τον κανονισμό (ΕΚ) αριθ. 2571/97 τη...\n",
              "8   The amount(s) of the processing securities mus...  Πρέπει συνεπώς να καθοριστούν το ή τα ποσά των...\n",
              "9   The measures provided for in this Regulation a...  Τα μέτρα που προβλέπονται στον παρόντα κανονισ...\n",
              "12  The minimum selling prices of butter from inte...  Για την 150η ειδική δημοπρασία στο πλαίσιο της...\n",
              "14  This Regulation shall enter into force on 16 O...  Ο παρών κανονισμός αρχίζει να ισχύει στις 16 Ο...\n",
              "15  This Regulation shall be binding in its entire...  Ο παρών κανονισμός είναι δεσμευτικός ως προς ό...\n",
              "20  to the Commission Regulation of 15 October 200...  του κανονισμού της Επιτροπής, της 15ης Οκτωβρί..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v2dgxX1bWg-"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.023)\n",
        "\n",
        "#36075 train | 925 test (0.025)#41034 train | 966 test (0.023)#51064 train | 936 test (0.018)#70992 train | 1008 test (0.014)#91080 train | 920 test (0.01)\n",
        "#31040 train | 960 test (0.03)#26055 train | 945 test (0.035)#21010 train | 990 test (0.045)#16150 train | 850 test (0.05)#11040 train | 960 test (0.08)\n",
        "#6020 train | 980 test (0.14)\n",
        "\n",
        "train, validation = train_test_split(train, test_size=0.023) \n",
        "\n",
        "#35173 train | 902 validation (0.025)#40090 train | 944 validation (0.023)#50145 train | 919 validation (0.018)#69998 train | 994 validation (0.014)#90169 train | 911 test (0.01)\n",
        "#30108 train | 932 validation (0.03)#25143 train | 912 validation (0.035)#20065 train | 945 validation (0.045)#15342 train | 808 validation (0.05)\n",
        "#10046 train | 994 validation (0.09)#5057 train | 963 validation (0.16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wZfjpsgPyj16"
      },
      "source": [
        "train.to_csv(\"train.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "test.to_csv(\"test.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "validation.to_csv(\"validation.csv\", index=False, encoding=\"utf-8-sig\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZI0BRBas0sY"
      },
      "source": [
        "spacy_eng = spacy.load(\"en\")\n",
        "spacy_el = spacy.load(\"el\")\n",
        "\n",
        "def tokenize_el(text):\n",
        "  return [token.text for token in spacy_el.tokenizer(text)]\n",
        "  \n",
        "def tokenize_eng(text):\n",
        "    return [token.text for token in spacy_eng.tokenizer(text)]\n",
        "\n",
        "english = Field(tokenize=tokenize_eng, init_token = \"<sos>\", eos_token = \"<eos>\", lower=True)\n",
        "greek = Field(tokenize=tokenize_el, init_token = \"<sos>\", eos_token = \"<eos>\", lower=True)\n",
        "\n",
        "fields = [(\"English\", english), (\"Greek\", greek)]\n",
        "\n",
        "train_data, test_data, valid_data = TabularDataset.splits(path=\"\", train=\"train.csv\", test=\"test.csv\", validation=\"validation.csv\", format=\"csv\", fields=fields)\n",
        "\n",
        "english.build_vocab(train_data, max_size=10000, min_freq=2)\n",
        "greek.build_vocab(train_data, max_size=10000, min_freq=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9IBfD74sOSu"
      },
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        embedding_size,\n",
        "        src_vocab_size,\n",
        "        tgt_vocab_size,\n",
        "        src_pad_idx,\n",
        "        nheads, #for the attention mechanism\n",
        "        num_encoder_layers,\n",
        "        num_decoder_layers,\n",
        "        dim_feedforward,\n",
        "        dropout,\n",
        "        max_len,\n",
        "        device,\n",
        "    ):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n",
        "        self.src_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "        self.tgt_word_embedding = nn.Embedding(tgt_vocab_size, embedding_size)\n",
        "        self.tgt_position_embedding = nn.Embedding(max_len, embedding_size)\n",
        "\n",
        "        self.device = device\n",
        "        self.transformer = nn.Transformer(\n",
        "            embedding_size,\n",
        "            nheads,\n",
        "            num_encoder_layers,\n",
        "            num_decoder_layers,\n",
        "            dim_feedforward,\n",
        "            dropout,\n",
        "        )\n",
        "        self.fc_out = nn.Linear(embedding_size, tgt_vocab_size)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.src_pad_idx = src_pad_idx\n",
        "\n",
        "    def make_src_mask(self, src): #If it is padded, there is no need to compute the padded values\n",
        "        # src: (src_len, N)\n",
        "        src_mask = src.transpose(0, 1) == self.src_pad_idx\n",
        "\n",
        "        # result: (N, src_len)\n",
        "        return src_mask.to(self.device)\n",
        "\n",
        "    def forward(self, src, tgt):\n",
        "        src_seq_length, N = src.shape\n",
        "        tgt_seq_length, N = tgt.shape\n",
        "\n",
        "        src_positions = torch.arange(0, src_seq_length).unsqueeze(1).expand(src_seq_length, N).to(self.device)  #Create positions for src embedding\n",
        "\n",
        "        tgt_positions = torch.arange(0, tgt_seq_length).unsqueeze(1).expand(tgt_seq_length, N).to(self.device)  #Create positions for tgt embedding\n",
        "\n",
        "        src = self.dropout(self.src_word_embedding(src) + self.src_position_embedding(src_positions))   # So that the network is aware of the order of words\n",
        "        \n",
        "        tgt = self.dropout(self.tgt_word_embedding(tgt) + self.tgt_position_embedding(tgt_positions))   # So that the network is aware of the order of words\n",
        "\n",
        "        src_padding_mask = self.make_src_mask(src)\n",
        "        tgt_mask = self.transformer.generate_square_subsequent_mask(tgt_seq_length).to(self.device)  # We mask the target input to the decoder so that the 1st output of the decoder only \n",
        "                                                                                                     # had access to the 1st element and then the 2nd output only had access to the 1st and \n",
        "                                                                                                     # 2nd input to the decoder.\n",
        "        out = self.transformer(\n",
        "            src,\n",
        "            tgt,\n",
        "            src_key_padding_mask=src_padding_mask,\n",
        "            tgt_mask=tgt_mask,\n",
        "        )\n",
        "        out = self.fc_out(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUvp8qcSvBrA"
      },
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 50\n",
        "learning_rate = 3e-4\n",
        "batch_size = 32\n",
        "src_vocab_size = len(greek.vocab)\n",
        "tgt_vocab_size = len(english.vocab)\n",
        "embedding_size = 512\n",
        "nheads = 8\n",
        "num_encoder_layers = 3\n",
        "num_decoder_layers = 3\n",
        "dropout = 0.10\n",
        "max_len = 200 \n",
        "dim_feedforward = 2048 #number of nodes in the feedforward network model\n",
        "src_pad_idx = english.vocab.stoi[\"<pad>\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BB9tYtccvBsc"
      },
      "source": [
        "train_iterator, test_iterator, valid_iterator = BucketIterator.splits(\n",
        "    (train_data, test_data, valid_data),\n",
        "    batch_size=batch_size,\n",
        "    sort_within_batch=True,\n",
        "    sort_key=lambda x: len(x.Greek),\n",
        "    device=\"cuda\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QtoNUuLvBuc"
      },
      "source": [
        "model = Transformer(\n",
        "    embedding_size,\n",
        "    src_vocab_size,\n",
        "    tgt_vocab_size,\n",
        "    src_pad_idx,\n",
        "    nheads,\n",
        "    num_encoder_layers,\n",
        "    num_decoder_layers,\n",
        "    dim_feedforward,\n",
        "    dropout,\n",
        "    max_len,\n",
        "    device,\n",
        ").to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXu-mzk4vBxz"
      },
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLb_wsJbvBz4"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, factor=0.1, patience=10, verbose=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vd1XOpGfvB3J"
      },
      "source": [
        "pad_idx = english.vocab.stoi[\"<pad>\"]\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o19fULcvBw5",
        "outputId": "29c93ec3-d44c-4d32-cbe6-044654e59e39"
      },
      "source": [
        "temp = -1\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"[Epoch {epoch} / {num_epochs}]\")\n",
        "    model.train()\n",
        "    losses = []\n",
        "    eval_losses = 0\n",
        "    for batch_idx, batch in enumerate(train_iterator):\n",
        "      \n",
        "        # Get input and targets to cuda\n",
        "        inp_data = batch.Greek.to(device)\n",
        "        target = batch.English.to(device)\n",
        "        if inp_data.shape[0] < 200 and target.shape[0] < 200:\n",
        "\n",
        "          # Forward propagation\n",
        "          output = model(inp_data, target[:-1, :])    # We want the target to be shifted, because when we send in the first element of the input\n",
        "                                                      # to be the start token we want the first output to correspond to the second element in the target.\n",
        "\n",
        "          # Output is of shape (tgt_len, batch_size, output_dim) but Crossentropy\n",
        "          # doesn't accept such input\n",
        "          # We need output_words * batch_size\n",
        "          # Also remove the start token\n",
        "          output = output.reshape(-1, output.shape[2])\n",
        "          target = target[1:].reshape(-1)\n",
        "\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          loss = criterion(output, target)  # Use Crossentropy for gradient,\n",
        "          losses.append(loss.item())        # but BLEU score for saving best model\n",
        "\n",
        "          # Back propagation\n",
        "          loss.backward()\n",
        "\n",
        "          # Clip to avoid exploding gradient issues\n",
        "          torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
        "\n",
        "          # Gradient descent step\n",
        "          optimizer.step()\n",
        "\n",
        "    model.eval()\n",
        "    score = bleu(valid_data[1:100], model, greek, english, device)\n",
        "    print(\"Validation Bleu score\", score*100)\n",
        "\n",
        "    mean_loss = sum(losses) / len(losses)\n",
        "    scheduler.step(mean_loss) # change learning rate\n",
        "\n",
        "    if score > temp:\n",
        "      temp = score\n",
        "      checkpoint = {\n",
        "          \"state_dict\": model.state_dict(),\n",
        "          \"optimizer\": optimizer.state_dict(),\n",
        "      }\n",
        "      print(\"Saving model...\")\n",
        "      torch.save(checkpoint, \"my_checkpoint.pth.tar\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch 0 / 50]\n",
            "Validation Bleu score 7.4042216021791205\n",
            "Saving model...\n",
            "[Epoch 1 / 50]\n",
            "Validation Bleu score 12.95580277545326\n",
            "Saving model...\n",
            "[Epoch 2 / 50]\n",
            "Validation Bleu score 18.19541147657579\n",
            "Saving model...\n",
            "[Epoch 3 / 50]\n",
            "Validation Bleu score 21.896437359169344\n",
            "Saving model...\n",
            "[Epoch 4 / 50]\n",
            "Validation Bleu score 27.998257114528464\n",
            "Saving model...\n",
            "[Epoch 5 / 50]\n",
            "Validation Bleu score 31.205713748931885\n",
            "Saving model...\n",
            "[Epoch 6 / 50]\n",
            "Validation Bleu score 34.2140008750644\n",
            "Saving model...\n",
            "[Epoch 7 / 50]\n",
            "Validation Bleu score 36.4376308830772\n",
            "Saving model...\n",
            "[Epoch 8 / 50]\n",
            "Validation Bleu score 35.63706784986916\n",
            "[Epoch 9 / 50]\n",
            "Validation Bleu score 38.02049667442805\n",
            "Saving model...\n",
            "[Epoch 10 / 50]\n",
            "Validation Bleu score 39.97228164770609\n",
            "Saving model...\n",
            "[Epoch 11 / 50]\n",
            "Validation Bleu score 39.55351930890009\n",
            "[Epoch 12 / 50]\n",
            "Validation Bleu score 39.29257191322627\n",
            "[Epoch 13 / 50]\n",
            "Validation Bleu score 40.32613886593779\n",
            "Saving model...\n",
            "[Epoch 14 / 50]\n",
            "Validation Bleu score 43.28416038451259\n",
            "Saving model...\n",
            "[Epoch 15 / 50]\n",
            "Validation Bleu score 42.23077701063615\n",
            "[Epoch 16 / 50]\n",
            "Validation Bleu score 41.618229870519585\n",
            "[Epoch 17 / 50]\n",
            "Validation Bleu score 42.93400039160896\n",
            "[Epoch 18 / 50]\n",
            "Validation Bleu score 45.87973989962178\n",
            "Saving model...\n",
            "[Epoch 19 / 50]\n",
            "Validation Bleu score 44.887911318782564\n",
            "[Epoch 20 / 50]\n",
            "Validation Bleu score 45.14073213253233\n",
            "[Epoch 21 / 50]\n",
            "Validation Bleu score 44.71998751616187\n",
            "[Epoch 22 / 50]\n",
            "Validation Bleu score 45.44135760047921\n",
            "[Epoch 23 / 50]\n",
            "Validation Bleu score 45.702150440339416\n",
            "[Epoch 24 / 50]\n",
            "Validation Bleu score 44.57551738660873\n",
            "[Epoch 25 / 50]\n",
            "Validation Bleu score 45.81226404031247\n",
            "[Epoch 26 / 50]\n",
            "Validation Bleu score 46.03312270470871\n",
            "Saving model...\n",
            "[Epoch 27 / 50]\n",
            "Validation Bleu score 46.23974177013014\n",
            "Saving model...\n",
            "[Epoch 28 / 50]\n",
            "Validation Bleu score 46.73689225195011\n",
            "Saving model...\n",
            "[Epoch 29 / 50]\n",
            "Validation Bleu score 46.86292171256971\n",
            "Saving model...\n",
            "[Epoch 30 / 50]\n",
            "Validation Bleu score 46.10074428379391\n",
            "[Epoch 31 / 50]\n",
            "Validation Bleu score 45.49490585614798\n",
            "[Epoch 32 / 50]\n",
            "Validation Bleu score 46.44658102985687\n",
            "[Epoch 33 / 50]\n",
            "Validation Bleu score 45.67969061595367\n",
            "[Epoch 34 / 50]\n",
            "Validation Bleu score 45.23585059427235\n",
            "[Epoch 35 / 50]\n",
            "Validation Bleu score 47.6306303848902\n",
            "Saving model...\n",
            "[Epoch 36 / 50]\n",
            "Validation Bleu score 45.49842199495149\n",
            "[Epoch 37 / 50]\n",
            "Validation Bleu score 45.33753704893009\n",
            "[Epoch 38 / 50]\n",
            "Validation Bleu score 47.176095138126044\n",
            "[Epoch 39 / 50]\n",
            "Validation Bleu score 47.4169574313018\n",
            "[Epoch 40 / 50]\n",
            "Validation Bleu score 47.31725470100046\n",
            "[Epoch 41 / 50]\n",
            "Validation Bleu score 48.6414286774433\n",
            "Saving model...\n",
            "[Epoch 42 / 50]\n",
            "Validation Bleu score 47.86944680800711\n",
            "[Epoch 43 / 50]\n",
            "Validation Bleu score 47.57330799436156\n",
            "[Epoch 44 / 50]\n",
            "Validation Bleu score 47.418183098166736\n",
            "[Epoch 45 / 50]\n",
            "Validation Bleu score 46.96218000556267\n",
            "[Epoch 46 / 50]\n",
            "Validation Bleu score 46.83133051084454\n",
            "[Epoch 47 / 50]\n",
            "Validation Bleu score 47.3825094769805\n",
            "[Epoch 48 / 50]\n",
            "Validation Bleu score 48.38298488897149\n",
            "[Epoch 49 / 50]\n",
            "Validation Bleu score 49.148808830206804\n",
            "Saving model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB9yyGoE5yxi"
      },
      "source": [
        "saved_model = torch.load(\"/content/my_checkpoint.pth.tar\")\r\n",
        "model.load_state_dict(saved_model[\"state_dict\"])\r\n",
        "optimizer.load_state_dict(saved_model[\"optimizer\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGYoArGNsOWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38ed8df6-294a-4b48-9f63-5d52a83d3fc8"
      },
      "source": [
        "# running on entire test data takes a while\n",
        "score = bleu(test_data[1:100], model, greek, english, device)\n",
        "print(\"Bleu score\", score*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bleu score 40.11381957984589\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2vhaptGpJaS"
      },
      "source": [
        "Greek\n",
        "\n",
        "Bleu score 45.06 | 90000\n",
        "\n",
        "Translated example sentence: \n",
        " ['main', 'network', 'of', 'the', 'network', '<.eos>']\n",
        "\n",
        "Bleu score 43.55 | 70000\n",
        "\n",
        "Translated example sentence: \n",
        " ['main', 'network', '<.eos>']\n",
        "\n",
        "Bleu score 24.52 | 50000\n",
        "\n",
        "Translated example sentence: ['agreed', 'place', 'of', 'delivery', 'in', 'arriving', 'country', '<.eos>']\n",
        "\n",
        "Bleu score 40.11| 40000\n",
        "\n",
        "Translated example sentence: \n",
        " ['i.', 'network', '<.eos>']\n",
        "\n",
        "Bleu score 50.99 | 35000\n",
        "\n",
        "Translated example sentence: \n",
        " ['the', 'network', 'of', 'the', 'network', 'of', 'services', '<.eos>']\n",
        "\n",
        "Bleu score 51.69 | 29000\n",
        "\n",
        "Translated example sentence: \n",
        " ['central', 'network', '<.eos>']\n",
        "\n",
        "Bleu score 47.33 | 25000\n",
        "\n",
        "Translated example sentence: \n",
        " ['vessels', '<.unk>', '<.eos>']\n",
        "\n",
        "Bleu score 44.06 | 20000\n",
        "\n",
        "Translated example sentence: \n",
        " ['<.unk>', 'ban', 'on', 'area', 'payment', '<.eos>']\n",
        "\n",
        "Bleu score 42.11 | 15000\n",
        "\n",
        "Translated example sentence: \n",
        " ['professional', 'secrecy', 'in', 'state', 'aid', 'decisions', '<.eos>']\n",
        "\n",
        "Bleu score 33.11 | 10000\n",
        "\n",
        "Translated example sentence: \n",
        " ['regular', 'way', 'purchase', 'or', 'sale', 'of', 'wine', '<.eos>']\n",
        "\n",
        "Bleu score 31.62 | 5000\n",
        "\n",
        "Translated example sentence: \n",
        " ['application', 'of', 'the', 'new', 'standards', 'should', 'remove', 'products', 'of', 'the', 'combined', 'nomenclature', '<.eos>']"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5HHH-8WMsOUy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c12dbab7-2064-4607-c269-543b4ec1435a"
      },
      "source": [
        "model.eval()\n",
        "sentence = \"Κεντρικό δίκτυο\"\n",
        "translated = translate(model, sentence, greek, english, device, max_length=50)\n",
        "print(\"Translated example sentence: \\n\", translated)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Translated example sentence: \n",
            " ['i.', 'network', '<eos>']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}